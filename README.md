# 视频流推理框架

## 项目简介

 `cv_inference_scheduler` 是一个视频流识别项目，旨在通过深度学习模型对视频流进行实时分析，支持目标检测、语义分割和关键点检测等任务。项目基于Python开发，使用FastAPI框架构建服务，支持ONNX和PyTorch模型。

## 功能特性

- **多模型支持**：项目可以加载和运行不同的深度学习模型，包括但不限于目标检测、语义分割和关键点检测模型。
- **实时视频流处理**：支持对RTSP、RTMP等视频流进行实时分析，可应用于监控摄像头视频流的处理。
- **单视频流多任务**：支持在单条视频流上设置不同类型的识别任务，同时不同任务可以设置不同的推理间隔。
- **灵活的模型管理**：通过配置文件管理模型信息，包括模型路径、任务类型、设备选择等，方便快捷地切换和管理不同的模型。
- **高性能**：利用ONNX Runtime进行模型推理，支持CPU和GPU两种运行模式，确保高效处理视频流。

## 安装与运行

1. **环境要求**：
   - Python 3.10+
   - ONNX Runtime
   - FastAPI
   - Uvicorn
   - OpenCV
   - 其他依赖见 `requirements.txt` 

2. **安装依赖**：
pip install -r requirements.txt
3. **运行服务**：
python start_object_detection_server.py
4. **容器化构建**：
运行 ./docker/build.sh 脚本，将构建一个名为 `cv-inference:v1.0` 的镜像。
运行 ./start_docker.sh 脚本，启动容器。

## 配置说明

项目的配置文件位于 `config.yml` ，包含服务的基本配置、模型列表等信息。用户可以根据需要修改配置文件，以加载不同的模型和调整服务参数。

## 模型支持

项目支持加载ONNX和PyTorch格式的模型。模型文件应放置在 `weights` 目录下，配置文件中指定模型路径、任务类型等信息。

- **目标检测**：使用 `YOLOv8` 类进行目标检测任务，支持加载 `.onnx` 和 `.pt` 格式的模型。
- **语义分割**：使用 `YOLOv8Seg` 类进行语义分割任务，支持加载 `.onnx` 和 `.pt` 格式的模型。
- **关键点检测**：使用 `YOLOv8Pose` 类进行关键点检测任务，支持加载 `.onnx` 和 `.pt` 格式的模型。

## API接口

服务运行后，提供以下API接口：

-  `/models` ：列出当前配置好的模型。
-  `/` ：此端点允许基于RTSP URL和模型名称删除进程，停止视频流检测。
-  `/inf` ：此断电设计用于进行推理请求。根据请求参数，它支持视频流处理和普通图像处理。

## 注意事项

- 确保模型文件与配置文件中的路径一致。
- 运行服务前，需要根据实际环境调整配置文件中的参数。

## 联系方式

如有问题或需要帮助，请通过以下方式联系：

- 邮箱：martin98@bu.edu

---
